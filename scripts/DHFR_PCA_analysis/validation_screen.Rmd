

```{r}
#### CHUNK 1 : Load packages ####

library(tidyverse)
library(magrittr)
library(bioseq)
library(ggpubr)
library(rstatix)
library(cowplot)
library(GGally)


non_syn_colour<- "skyblue2"  
stop_colour<-"#D81B60"
syn_colour<-"#ffc107"
wt_colour<-"#004D40"

```


```{r}

#### CHUNK 2 : Set parameters ####

#Values for validation screen
info<-read.csv("../../Data/DMS/designs/validation_design.csv")%>% 
   filter(target == "Pbs2")  

codon_output_file<-"../../Data/DMS/results/codon_validation_scores.csv"
aa_output_file<-"../../Data/DMS/results/aa_validation_scores.csv"
  
#Files with the wt codon sequence and aa sequence
pbs2_wt_seq<-read.csv("../../Data/DMS/reference/Pbs2_wt_seq.csv")%>%
  mutate(position=position+70)

wt_reads_path<-"../../Data/DMS/variant_counts/validation_variant_count/wt_counts.csv"
extended_motif_screen_path<-"../../Data/DMS/results/aa_extended_motif_DMS_scores.csv"
surrounding_region_results_path<-"../../Data/DMS/results/aa_surrounding_region_DMS_scores.csv"
growth_curves_results_path<-"../../Data/growthcurves/results_validation_growth_curves.csv"

#File containing list of reconstructed mutants
reconstructed_mutants<-read.csv("../../Data/DMS/reference/reconstructed_strains.csv")

```




```{r}
#### CHUNK 3 : Import variant counts ####

#This chunk imports all the reads per mutant from all the libraries, and combines into one dataframe 

df<-data.frame()
for(i in 1:nrow(info)){
  
  current_file<-info[i, "file"]
  
    current_df<-read.csv(current_file, col.names = c("codon", 71:126), header=F, skip=1, check.names = F)
  
  
  # import the file with the right number of codons depending on the length of DMS
  
  #Change to long format, add the aa the codon codes for and library number, then join the relevant information from info df
  current_df %<>%
    pivot_longer(cols=-codon, names_to = "position", values_to = "reads", names_transform =  as.integer)%>%
    mutate(aa=as.character(bioseq::seq_translate(bioseq::dna(codon))),
           library=info[i, "library"]) %>%
    left_join(., info, by="library")
  
  #add to the df of all libraries 
  df<-rbind(df, current_df)
}
rm(current_df, i, current_file)

```

```{r}

#### CHUNK 4 : Identify mutation types ####

###Identify each mutant as Wt, Synonymous, non-synonymous or STOP

#Combine the WT sequences together to do both proteins in the same command
pbs2_wt_seq<-pbs2_wt_seq %>% 
          mutate(codon_type="WT", aa_type="WT")

#Join df with the WT sequence to indicate which codons and aa are Wt. Then indicate whether position is WT, synonymous, STOP or non-synonymous depending on the WT of codon and aa, and aa identity.
df %<>%   left_join(., select(pbs2_wt_seq, -c(aa, aa_type)), by=c("position", "target", "codon")) %>%
          left_join(., select(pbs2_wt_seq, -c(codon, codon_type)), by=c("position", "target", "aa")) %>%
          mutate(type=  case_when(codon_type == "WT" & aa_type == "WT" ~ "WT",
                                  is.na(codon_type) & aa_type == "WT" ~ "Syn",
                                  aa == "*" ~ "STOP",
                                  is.na(codon_type) & is.na(aa_type) & aa != "*" ~ "Non-Syn")) %>%
          select(-c(codon_type, aa_type))
  
```

```{r}

#### CHUNK 5 : Add WT counts ####



# Create a line in each library for WT, here randomly assigned to I87

df<-filter(df, type != "WT") #Remove WT from original DF

#Keep a version with one line per library with all identifying information
reduced_df<-df%>%
  select(-c(codon, position, reads, aa, type))%>%
  distinct()

#Import Wt reads, and assign arbitrary values for 1 Wt codon, for comparing with other screens
wt_reads<-read.csv(wt_reads_path, col.names = c("library", "reads"))
wt_reads_filled<-wt_reads%>%
  mutate(codon = "ATT", position =87, aa="I", type = "WT")%>%
  left_join(reduced_df, ., by="library")

df<-bind_rows(df, wt_reads_filled)


rm(wt_reads_filled, reduced_df)
```

```{r}

#### CHUNK 6 : Bring reads to 1####

#Many of the possible mutations have zero reads after selection, and so appear as NA. However, these are mutations which are the most selected against, and should show up. I will therefore replace the NA reads by 1 read, which is the lowest which allows calculation of a selection coefficient. For the S2 reads, even if brought up to 1, they will be filtered out, as they are less than 20

df$reads <- tidyr::replace_na(df$reads, 1) 

```



```{r}
#### CHUNK 7 : Only keep reconstructed mutants####
#Filter validation_screen

reconstructed_mutants<-reconstructed_mutants%>%
  pivot_longer(cols = c("None", "Hog1", "Sho1"), names_to = "interactor", values_to="present")%>%
  mutate(position=as.numeric(str_replace_all(mutant, "[:alpha:]|[:punct:]", "")),
         aa=str_sub(mutant, start=-1, end=-1))%>%
  mutate(position = case_when(mutant == "WT" ~ 87,    #For joining of the WT  
                              TRUE ~ position),
         aa = case_when(mutant == "WT" ~ "I",    
                        TRUE ~ aa))

#Only keep the mutants that were reconstructed, the others are probably sequencing errors
df<-df%>%
  left_join(reconstructed_mutants, df, by=c("interactor", "position", "aa"))%>% 
  filter(present==1)
  
df<-df%>%
  group_by(position, aa, library)%>%
  slice_max(order_by = reads, n = 1, with_ties=F)%>% #Only keep the mutant with the most reads per aa,
  ungroup()                                                                            #this removes codons synonymous                                                                                       #to the constructed ones
#These mutants do not correlate between replicates, remove from screen
df<-df%>%
  filter(!(mutant %in% c("V100I", "L98V", "L95R", "P99C")))

rm(reconstructed_mutants)

```



```{r}

#### CHUNK 8 : Normalize read counts ####

#Normalize by dividing number of reads for each mutation by the number of total reads in the library. Taking frequency of mutation essentially.


total_reads <- df %>%
           group_by(library) %>%
           summarise(total_reads_in_library = sum(as.numeric(reads), na.rm=T))



df %<>%    left_join(., total_reads, by="library") %>%        
           select(-wt_reads)%>%                                   #Remove the WT reads that comes automatically from the info sheet
           left_join(., wt_reads%>%rename(wt_reads=reads), by="library")%>%     #Replace with the calculated wt reads per library
           mutate(norm_final_reads = reads/total_reads_in_library, norm_final_wt_reads = wt_reads/total_reads_in_library) 
#For WT reads, take the frequency of WT, because what we really want to measure are allele frequencies

rm(total_reads)
      

```


```{r, warning=F, message=F}

#### CHUNK 9 : Check correlation between libraries ####

log2_df <- df %>% mutate(log_norm_reads = log2(norm_final_reads))

ggplot(log2_df, aes(x=log_norm_reads, colour=interaction(condition, sorbitol, interactor)))+
  geom_density()+
  #facet_wrap(~target)+
  scale_colour_viridis_d(option="turbo")

#What is the read count for each variant for the different libraries?
log2_df%>%
  ggplot(aes(x=as.factor(library), y=log2(reads), fill=condition, colour=interactor))+
  geom_violin()+
  scale_colour_viridis_d()+
  theme_bw()+
  labs(title="Distribution of read counts for each library")

#What is the frequency distribution for each variant in each library?
log2_df%>%
  ggplot(aes(x=as.factor(library), y=log_norm_reads, fill=condition, colour=interactor))+
  geom_violin()+
  scale_colour_viridis_d()+
  theme_bw()+
  labs(title="Variant frequency distribution for each library")


log2_df%>%select(codon, position, condition, interactor, sorbitol, replicate, log_norm_reads)%>%
  pivot_wider(names_from = replicate, values_from = log_norm_reads)%>%
  ggpairs(columns = 6:ncol(.))

#Check the correlation between number of reads for mutations in all libraries
cor_df_prep<- log2_df %>%
           unite(col="identifier", target, condition, sorbitol, interactor, replicate, strain_background, remove = FALSE) %>%
           select(identifier, log_norm_reads, position, codon) %>%
           pivot_wider(names_from = identifier, values_from = log_norm_reads)
  
cor_df <- as.data.frame(cor(cor_df_prep[,-c(1,2)], method="spearman", use="pairwise.complete.obs")) %>%
          mutate(lib1=colnames(cor_df_prep[,-c(1,2)])) %>%
          pivot_longer(cols=-lib1, names_to = "lib2", values_to = "cor.coef")

#Heatmap of correlation matrix
cor_heatmap<-ggplot(cor_df, aes(x=lib1, y=lib2, fill=cor.coef))+
  geom_tile(colour="grey50")+
    scale_fill_gradient2(low="blue", mid="white", high="red")+
  scale_x_discrete(position="top", expand=c(0,0), limits=colnames(cor_df_prep[,-c(1,2)]))+
  scale_y_discrete(expand=c(0,0), limits=rev(colnames(cor_df_prep[,-c(1,2)])))+
  #theme(axis.text.x = element_text(angle=90, hjust=0, vjust=0))+
  guides(x=guide_axis(angle=45))+
  labs(x="", y="", 
      fill="rho")+
  coord_fixed(ratio=1)

cor_heatmap




rm(cor_df_prep, cor_df, log2_df, cor_heatmap)
```


```{r}

#### CHUNK 10 : Add initial timepoint ####

#Organise the initial timepoints (S2) so that I can add them back as a column
ini_df<-df %>%
        filter(condition == "S2") %>%
        rename(norm_ini_reads = norm_final_reads, norm_ini_wt_reads = norm_final_wt_reads, S2_reads = reads) %>%
        select(c(codon, position, S2_reads, norm_ini_reads, replicate, target, interactor, norm_ini_wt_reads, strain_background))

#Add the initial timepoints back as a column, then remove the initial timepoint rows
df %<>% left_join(., ini_df, by=c("codon", "position", "replicate", "target", "interactor", "strain_background")) %>%
        filter(condition != "S2")

rm(ini_df)


```

```{r, message=F, warning=F}

#### CHUNK 11 : Calculate variant scores ####

#first find the number of generations for each library, then calculate selection coefficient and log2FC
df %<>%   mutate(gens=log2(first_selection_final_OD/0.1)+log2(second_selection_final_OD/0.1))%>%
            mutate(selection_coefficient = (log(norm_final_reads/norm_ini_reads)-log(norm_final_wt_reads/norm_ini_wt_reads))/gens,
                   log2FC=log2(norm_final_reads/norm_ini_reads)) %>%
          mutate(library = paste0("library_", library)) %>%
          unite(col="identifier", target, condition, sorbitol, interactor, replicate, strain_background, remove = FALSE)   



#Calculate the correlation between selection coefficients of all libraries
cor_df_prep<- df %>%
           select(identifier, selection_coefficient, position, codon) %>%
           pivot_wider( names_from = identifier, values_from = selection_coefficient)
  
cor_df <- as.data.frame(cor(cor_df_prep[,-c(1,2 )], method="spearman", use="pairwise.complete.obs")) %>%
          mutate(lib1=colnames(cor_df_prep[,-c(1,2)])) %>%
          pivot_longer(cols=-c(lib1, ), names_to = "lib2", values_to = "cor.coef")

#Correlation matrix of selection coefficients as heatmap
g<-ggplot(cor_df, aes(x=lib1, y=lib2, fill=cor.coef))+
  geom_tile(colour="grey50")+
    scale_fill_gradient(low="white", high="blue")+
  scale_x_discrete(position="top", expand=c(0,0), limits=colnames(cor_df_prep[,-c(1,2)]))+
  scale_y_discrete(expand=c(0,0), limits=rev(colnames(cor_df_prep[,-c(1,2)])))+
  theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))+
  labs(x="", y="", 
      fill="rho")+
  guides(x=guide_axis(angle=45))+
  coord_fixed(ratio=1)
g

df%>%select(codon, position, condition, interactor, sorbitol, replicate, log2FC)%>%
  pivot_wider(names_from = replicate, values_from = log2FC)%>%
  ggpairs(columns = 6:ncol(.))


df<-df%>%
  filter(aa != "*" | position != 98 | replicate != 5 | sorbitol != 0 | condition != "Stress")

#Rescale log2FC scores
rescaled_df<-data.frame()
for (i in unique(df$library)){
  current_df<-filter(df, library == i) #One library at a time
  
  current_wt_value<-current_df%>%      #Get WT log2FC
    filter(type == "WT")%>%
    pull(log2FC)%>%
    unique()
  
  current_stop<-current_df%>%          #Get median STOP log2FC
    filter(type=="STOP")%>%
    pull(log2FC)%>%
    median(na.rm=T)
  
 
                                      #Rescale log2FC. STOP =-1 and WT=0
  modified_df<-current_df%>%
    mutate(log2FC = ((log2FC-current_stop)/(current_wt_value-current_stop))*(0--1)+-1)
  
  rescaled_df<-bind_rows(rescaled_df, modified_df)
}




rm(cor_df_prep, cor_df, g, current_wt_value, current_df, current_stop, modified_df)





```




```{r}

#### CHUNK 12 : Filter by initial reads ####

#Does the number of initial reads influence the selection coefficient calculated?


ggplot(rescaled_df, aes(y=log2FC, x=log2(S2_reads)))+
  geom_point(shape=21, alpha=0.5, aes(colour=type))+
  geom_smooth(colour="black", method="lm")+
  stat_cor(method = "spearman", cor.coef.name = "rho")



#Cut all variants that do not have at least twenty reads detected at initial timepoint
cut_df <- rescaled_df %>%
            filter(S2_reads >=20) %>%
            unite("identifier", target, condition, sorbitol, interactor, strain_background, remove=F)

#Does the frequency of initial reads bias the log2FC after quality control
ggplot(cut_df, aes(y=log2FC, x=log2(S2_reads)))+
  geom_point(shape=21, alpha=0.5, aes(colour=type))+
  geom_smooth(colour="black", method="lm")+
  stat_cor(method = "spearman", cor.coef.name = "rho")

```


```{r, message=F, warning=F}

#### CHUNK 13 : Combine to aa ####
cut_df%>%
  select(codon, position, condition, interactor, sorbitol, replicate, log2FC)%>%
  pivot_wider(names_from = replicate, values_from = log2FC)%>%
  ggpairs(columns = 6:ncol(.), mapping = aes(colour=interactor))


#Combine replicates and codons together to get aa level stats. Only take AA with at least 2 replicates passing quality control
cut_comb_df<- cut_df %>%
          group_by(position, target, condition, sorbitol, interactor, aa, strain_background, type, mutant) %>%
          summarize(median_sel_coeff = median(selection_coefficient, na.rm = T),
                    replicates_per_aa = n(),
                    median_log2FC=median(log2FC, na.rm=T),
                    sd_log2FC=sd(log2FC, na.rm=T),
                    sd_sel_coeff = sd(selection_coefficient, na.rm = T),
                    min_S2_reads = min(S2_reads, na.rm=T)) %>%
          filter(replicates_per_aa >= 2) %>%
          unite("identifier", target, condition, sorbitol, interactor, strain_background, remove=F)





```

```{r}

#### CHUNK 14 : Visualize scores ####


#Interaction scores for validation mutants
cut_df%>%
  filter(condition=="MTX")%>%
  ggplot(aes(x=mutant, y=log2FC))+
  geom_boxplot(aes(colour=as.factor(sorbitol)))+
  theme_bw()+
  facet_grid(rows=vars(interactor))+
  theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))+
  ggtitle("Interaction assay")


#Selection coefficient for validation mutants (proliferation assay)
cut_df%>%
  filter(condition=="Stress")%>%
  ggplot(aes(x=mutant, y=selection_coefficient))+
  geom_boxplot(aes(colour=as.factor(sorbitol)))+
  #geom_point(aes(colour=as.factor(sorbitol), shape=as.factor(replicate)))+
  theme_bw()+
  theme(axis.text.x = element_text(angle=90, vjust=0.5, hjust=1))+
  ggtitle("Proliferation assay")





```





```{r}

#### CHUNK 15 : Significance of scores ####

#Are any of the interaction effects significantly stronger/weaker than WT and synonymous?

#Add p-value for interaction score
interaction_t_test<-cut_df%>%
  filter(condition == "MTX" & interactor == "Sho1")%>%
  dplyr::mutate(t_test_type=case_when(type %in% c("Non-Syn", "STOP") ~ mutant, #Separate Non-syn mutants,
                                   type %in% c("WT", "Syn") ~ "Syn+WT"))%>%          #the "reference" is WT+Syn pooled
  group_by(sorbitol)%>%                                       #Group for T-test
  rstatix::pairwise_t_test(log2FC ~ t_test_type,                      # Compare the sel coeff of mutants
                                ref.group = "Syn+WT",                                #Compare Non-syn mutants against Syn+WT   
                                p.adjust.method = "fdr",                             #Correction for multiple corrections
                                alternative ="two.sided",                            #Two-sided t-test 
                           pool.sd=F, var.equal=F)%>%                                #Welch's correction as var is unequal
  rename(mutant = group2, p.signif.interaction=p.adj.signif, p.adj.interaction=p.adj)     #For joining later


cut_df%>%
  filter(condition =="MTX" & interactor == "Sho1" & sorbitol ==1)%>%
  ggplot(aes(x=mutant, y=log2FC))+
  geom_boxplot(aes(fill=type))+
  geom_text(data=interaction_t_test%>%filter(sorbitol ==1 & p.signif.interaction != "ns"), aes(x=mutant, y=2, label=p.signif.interaction))+
  scale_fill_manual(values = c(non_syn_colour, stop_colour, syn_colour, wt_colour), labels=c("Missense", "Nonsense", "Silent", "WT"), name="Mutation type" )+
  theme_bw()+
  theme(axis.text.x = element_text(angle=90, hjust=1, vjust=0.5))+
  labs(y="Interaction score",
       x="Mutant")



#Are any of the fitness effects significantly stronger/weaker than WT and synonymous?

#Add p-value for sel_coeff
sel_coeff_t_test<-cut_df%>%
  filter(condition == "Stress")%>%
  dplyr::mutate(t_test_type=case_when(type %in% c("Non-Syn", "STOP") ~ mutant, #Separate Non-syn mutants,
                                   type %in% c("WT", "Syn") ~ "Syn+WT"))%>%          #the "reference" is WT+Syn pooled
  group_by(sorbitol)%>%                                       #Group for T-test
  rstatix::pairwise_t_test(selection_coefficient ~ t_test_type,                      # Compare the sel coeff of mutants
                                ref.group = "Syn+WT",                                #Compare Non-syn mutants against Syn+WT   
                                p.adjust.method = "fdr",                             #Correction for multiple corrections
                                alternative ="two.sided",                            #Two-sided t-test 
                           pool.sd=F, var.equal=F)%>%                                #Welch's correction as var is unequal
  rename(mutant = group2, p.signif_sel_coeff=p.adj.signif, p.adj.sel_coeff=p.adj)     #For joining later


cut_df%>%
  filter(condition =="Stress" & sorbitol ==1)%>%
  ggplot(aes(x=mutant, y=selection_coefficient))+
  geom_boxplot(aes(fill=type))+
  geom_text(data=sel_coeff_t_test%>%filter(sorbitol ==1 & p.signif_sel_coeff != "ns"), aes(x=mutant, y=0.1, label=p.signif_sel_coeff))+
  scale_fill_manual(values = c(non_syn_colour, stop_colour, syn_colour, wt_colour), labels=c("Missense", "Nonsense", "Silent", "WT"), name="Mutation type" )+
  theme_bw()+
  theme(axis.text.x = element_text(angle=90, hjust=1, vjust=0.5))+
  labs(y="Selection coefficient",
       x="Mutant")


```

```{r}

#### CHUNK 16 : Correlation with previous screens ####

#Check correlation with extended motif-only screen

motif_screen<-read.csv(extended_motif_screen_path)

renamed_df<-cut_comb_df%>%
  ungroup()%>%
  select(position, condition, sorbitol, interactor, aa, mutant, median_sel_coeff, median_log2FC)%>%
  rename(validation_sel_coeff=median_sel_coeff, validation_log2FC=median_log2FC)


compared_motif<-inner_join(motif_screen, renamed_df, by=c("position", "condition", "sorbitol", "interactor", "aa"))

compared_motif%>%
  filter(type != "WT")%>%
  # filter(condition =="Stress")%>%
ggplot(aes(x=median_sel_coeff, y=validation_sel_coeff, colour=interactor))+
  geom_point(aes(group=mutant))+
  stat_cor(method="spearman", cor.coef.name = "rho", show.legend = F, label.y.npc = 0.5)+
  facet_grid(rows=vars(sorbitol), cols=vars(condition))+
  labs(title="Correlation with extended motif screen")



#Check correlation with surrounding region screen
preliminary_screen<-read.csv(surrounding_region_results_path)


compared_preliminary<-inner_join(preliminary_screen, renamed_df, by=c("position", "condition", "sorbitol", "interactor", "aa"))

compared_preliminary%>%
  filter(type != "WT")%>%
  ggplot(aes(x=median_sel_coeff, y=validation_sel_coeff, colour=interactor))+
  geom_point(aes(group=mutant))+
  stat_cor()+
  facet_grid(rows=vars(sorbitol), cols=vars(condition))+
  labs(title="Correlation with surrounding region screen")



```

```{r}

#### CHUNK 17 : Correlation with growth curves ####

#Check correlation with growth curves

growthcurves<-read.csv(growth_curves_results_path)%>%
  mutate(sorbitol=case_when(condition == "Sorbitol" ~1,
                            condition == "None" ~ 0))%>%
  select(-condition)%>%
  group_by(mutation, sorbitol)%>%
  summarize(median_mtx_gr=median(mtx_gr, na.rm=T),
            median_dmso_gr=median(dmso_gr, na.rm=T))%>%
  rename(mutant = mutation)


compared_gc<-cut_comb_df%>%
  filter(interactor != "Hog1")%>%
  select(condition, sorbitol, interactor, type, mutant, median_log2FC, median_sel_coeff)%>%
  pivot_wider(names_from=c(condition, interactor), values_from = c(median_log2FC, median_sel_coeff))%>%
  inner_join(., growthcurves, by=c("mutant", "sorbitol"))
  

#MTX in validation vs MTX growth curves
compared_gc%>%
  ggplot(aes(x=median_log2FC_MTX_Sho1, y=median_mtx_gr, colour=as.factor(sorbitol)))+
  geom_point(aes(group=interaction(aa, position)))+
  stat_cor(method="spearman", cor.coef.name = "rho")+
  labs(x="Validation screen Sho1 interaction score MTX",
       y="Growth curves MTX growth rate")


```


```{r}

#### CHUNK 18 : Export results ####

write.csv(file=aa_output_file, x=cut_comb_df , row.names = F)

write.csv(file=codon_output_file, x=cut_df, row.names = F)
```



